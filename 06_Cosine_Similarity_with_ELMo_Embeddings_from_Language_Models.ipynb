{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "D8itbuZD_fcL",
      "metadata": {
        "id": "D8itbuZD_fcL"
      },
      "source": [
        "# Embeddings from Language Models (ELMo)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "331e225a",
      "metadata": {
        "id": "331e225a"
      },
      "source": [
        "# Acknowledgment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pRazJp5K7g99",
      "metadata": {
        "id": "pRazJp5K7g99"
      },
      "source": [
        "This Google Colab has been created by **`Manuel Escola`** using the library created by **`Dani El-Ayyass`** and **`Andrey Kutuzov`**. You can find all the documentation at https://github.com/ltgoslo/simple_elmo.\n",
        "\n",
        "<br />\n",
        "<img style=\"width: 30%; padding-left: 11rem;\" width=\"30%\" src=\"https://drive.google.com/uc?id=1j7mUForsRLryX7CCQOOiYVB4W-c0mmnc\" />\n",
        "<!-- <img style=\"width: 30%; padding-left: 11rem;\" src=\"img/contextual-elmo-icon.gif\" /> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e7061af",
      "metadata": {},
      "source": [
        "_Note: This notebook has been designed to be run in Google Collab. If run it locally or in other platforms, please make sure the libraries are correctly installed in your machine and the datasets are loaded correctly into the notebook._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29a782a",
      "metadata": {
        "id": "f29a782a"
      },
      "source": [
        "# Installing Simple ELMo library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "66c21516",
      "metadata": {
        "id": "66c21516",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade simple_elmo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "136ca3d3",
      "metadata": {
        "id": "136ca3d3"
      },
      "source": [
        "# Importing pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5e6e17fe",
      "metadata": {
        "id": "5e6e17fe"
      },
      "outputs": [],
      "source": [
        "from simple_elmo import ElmoModel\n",
        "\n",
        "model = ElmoModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "adc84c9a",
      "metadata": {
        "id": "adc84c9a"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# https://drive.google.com/file/d/1ILVz0nq5gJ3ZxbvHyU1osUZ4vuBdAgQ7/view?usp=sharing\n",
        "! gdown --id 1ILVz0nq5gJ3ZxbvHyU1osUZ4vuBdAgQ7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "NwzE5a_h5c5M",
      "metadata": {
        "id": "NwzE5a_h5c5M"
      },
      "outputs": [],
      "source": [
        "PATH_TO_ELMO = '/content/ELMo.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e4cd54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9e4cd54",
        "outputId": "d0999c4c-f9b3-437c-a9f8-84868499e398",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/simple_elmo/model.py:531: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  lstm_cell = tf.compat.v1.nn.rnn_cell.LSTMCell(\n"
          ]
        }
      ],
      "source": [
        "model.load(PATH_TO_ELMO)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c87203f",
      "metadata": {
        "id": "3c87203f"
      },
      "source": [
        "# Creating useful functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DfljPGHF8dLC",
      "metadata": {
        "id": "DfljPGHF8dLC"
      },
      "source": [
        "First, we created some useful functions to tokenise sentences at word level and find the position of a certain word (the one we want to compare) within each sentence. For better tokenisation, you can use the `SpaCy` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c5567c5",
      "metadata": {
        "id": "9c5567c5"
      },
      "outputs": [],
      "source": [
        "def sentence_to_words(sentence):\n",
        "    '''\n",
        "    This function splits sentences into a list with words.\n",
        "    If there is some comma or dot, the comma or dot is deleted\n",
        "    from the sentence.\n",
        "    '''\n",
        "    # Remove commas and dots\n",
        "    sentence = sentence.replace(',', '').replace('.', '')\n",
        "\n",
        "    # Split the sentence into words and return the list\n",
        "    return sentence.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20a0ad5",
      "metadata": {
        "id": "d20a0ad5"
      },
      "outputs": [],
      "source": [
        "# Testing the function\n",
        "\n",
        "sentence1 = \"When I arrived, she already had left\"\n",
        "sentence2 = \"I write with my left hand\"\n",
        "\n",
        "sentence_1 = sentence_to_words(sentence1)\n",
        "sentence_2 = sentence_to_words(sentence2)\n",
        "\n",
        "print(sentence_1)\n",
        "print(sentence_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ae9dcf",
      "metadata": {
        "id": "b4ae9dcf"
      },
      "outputs": [],
      "source": [
        "def find_word_indices(sentences, word):\n",
        "    '''\n",
        "    This function returns the index (on each sentence)\n",
        "    of the word to compare\n",
        "\n",
        "    Input: a list with the sentences (already tokenized)\n",
        "    Output: index of the word within each sentence\n",
        "    '''\n",
        "    indices = []\n",
        "    for sentence in sentences:\n",
        "        try:\n",
        "            # Find the index of the word in the sentence\n",
        "            word_index = sentence.index(word)\n",
        "            indices.append(word_index)\n",
        "        except ValueError:\n",
        "            # If the word is not found, you can append None or -1, or handle as needed\n",
        "            indices.append(None)\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5f2e66",
      "metadata": {
        "id": "9f5f2e66"
      },
      "outputs": [],
      "source": [
        "# Testing the function\n",
        "\n",
        "word_to_find = \"left\"\n",
        "\n",
        "SENTENCES = [sentence_1,\n",
        "             sentence_2]\n",
        "\n",
        "find_word_indices(SENTENCES, word_to_find)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c29644",
      "metadata": {
        "id": "c4c29644"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jblqHst_8yuO",
      "metadata": {
        "id": "jblqHst_8yuO"
      },
      "source": [
        "We use the first function to transform the sentences into a list of words (i.e., we tokenise the sentences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed45fc1d",
      "metadata": {
        "id": "ed45fc1d"
      },
      "outputs": [],
      "source": [
        "sentence1 = \"When I arrived, she already had left\"\n",
        "sentence2 = \"I write with my left hand\"\n",
        "\n",
        "sentence_1 = sentence_to_words(sentence1)\n",
        "sentence_2 = sentence_to_words(sentence2)\n",
        "print(sentence_1)\n",
        "print(sentence_2)\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be5a14cc",
      "metadata": {
        "id": "be5a14cc"
      },
      "outputs": [],
      "source": [
        "# We save the two lists of words (tokenized sentence) into a new list\n",
        "\n",
        "SENTENCES = [sentence_1,\n",
        "             sentence_2]\n",
        "\n",
        "num_sentences = len(SENTENCES)\n",
        "num_words = max(len(sentence_1), len(sentence_2))\n",
        "\n",
        "print(f'The number of sentences is {num_sentences}')\n",
        "print(f'The number of words in longer sentence is {num_words}')\n",
        "print(f'The length of the embedding for each word is always 1024 in this ELMo version')\n",
        "print('\\n')\n",
        "print(f'The shape of the array returned by the model should be: ({num_sentences}, {num_words}, 1024)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "226ebdce",
      "metadata": {
        "id": "226ebdce"
      },
      "source": [
        "# Implementing model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rJTzsL6U89TJ",
      "metadata": {
        "id": "rJTzsL6U89TJ"
      },
      "source": [
        "We use the model to transform each word in the sentences into a vector that contains 1024 values (the number 1024 is given by default by the model, but some libraries allow to change this number to any different one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a7bb982",
      "metadata": {
        "id": "6a7bb982",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "result = model.get_elmo_vectors(SENTENCES)\n",
        "print(f'The shape is: {result.shape}, as expected')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b702f3",
      "metadata": {
        "id": "e7b702f3"
      },
      "source": [
        "# Finding the embeddings of the word to compare (second function)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PCSA69ts9RB4",
      "metadata": {
        "id": "PCSA69ts9RB4"
      },
      "source": [
        "We find the index of the word whose embedding (vector) we want to compare in both sentences. <br>\n",
        "* **Note**: Remember that the word is represented by a different vector within each sentence because the vector is created considering the context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f416da1",
      "metadata": {
        "id": "1f416da1"
      },
      "outputs": [],
      "source": [
        "word_to_find = \"left\"\n",
        "indices = find_word_indices(SENTENCES, word_to_find)\n",
        "print(f'The index of the word \"{word_to_find}\" in sentence 1 is {indices[0]}')\n",
        "print(f'The index of the word \"{word_to_find}\" in sentence 2 is {indices[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd5e019b",
      "metadata": {
        "id": "bd5e019b"
      },
      "source": [
        "# Compute the cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5cf9795",
      "metadata": {
        "id": "a5cf9795"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# sentence 1\n",
        "embed_1 = result[0][indices[0]] # First element of the list\n",
        "# sentence 2\n",
        "embed_2 = result[1][indices[1]] # Second element of the list\n",
        "\n",
        "# Reshape the embeddings to 2D arrays of shape [1, 1024]\n",
        "embed_1_reshaped = np.reshape(embed_1, (1, -1))\n",
        "embed_2_reshaped = np.reshape(embed_2, (1, -1))\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity = cosine_similarity(embed_1_reshaped, embed_2_reshaped)[0][0]\n",
        "print(\"The cosine similarity for word '{}' is: {:.4f}\".format(word_to_find, similarity))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
